{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Helpful) References\n",
    "\n",
    "* http://cs231n.stanford.edu/vecDerivs.pdf\n",
    "* https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The derivative of a vector-valued function $\\vec h(x,W)$  w.r.t. to some weight-matrix $W$\n",
    "\n",
    "Suppose the following setup:\n",
    "\n",
    "<img style=\"max-width:400px;\" src=\"https://i.imgur.com/sG5UBMq.png\"></img>\n",
    "\n",
    "$\\vec h$ is a vector-valued function. We're looking for the derivative $\\frac{\\partial \\vec h}{\\partial W}$. This requires us to calculate partial derivatives of *each* element of h with respect to *each* element of W. In total, we have to compute `3*(2*3)=18` partial derivatives. We can store these 18 derivatives in three (2x3) matrices. These matrices will store the partial derivatives of $\\frac{\\partial h_1}{\\partial W}, \\frac{\\partial h_2}{\\partial W}, \\frac{\\partial h_3}{\\partial W}$.\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/oPLzvtc.png\"></img>\n",
    "\n",
    "When computing the elements of the matrices, we note that the following pattern emerges:\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/YZ7T3SQ.png\"></img>\n",
    "\n",
    "Using this, we can compute the partial derivatives:\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/thOmApu.png\"></img>\n",
    "\n",
    "These three matrices can now be used to update `W`. To update `W`, we would need to do three steps:\n",
    "\n",
    "1. $W = W - \\text{learning_rate}\\cdot \\frac{\\partial h_1}{\\partial W}$\n",
    "1. $W = W - \\text{learning_rate}\\cdot \\frac{\\partial h_2}{\\partial W}$\n",
    "1. $W = W - \\text{learning_rate}\\cdot \\frac{\\partial h_3}{\\partial W}$\n",
    "\n",
    "or, equivalently,\n",
    "\n",
    "$$\n",
    "W = W - \\text{learning_rate}*(\\frac{\\partial h_1}{\\partial W} + \\frac{\\partial h_2}{\\partial W} + \\frac{\\partial h_3}{\\partial W})\n",
    "$$\n",
    "\n",
    "But there is a trick (see Section 3 of http://cs231n.stanford.edu/vecDerivs.pdf) that (1) simplifies the update-step and (2) helps storing the three matrices more efficiently. For this trick, note that most elements of the three matrices are zero. In fact, the only non-zero elements $\\frac{\\partial h_i}{\\partial W_{jk}}$ of $\\frac{\\partial h_i}{\\partial W}$ are those elements where $i=k$. We could define a new matrix $J_{j,i}=\\frac{\\partial h_i}{\\partial W_{ji}}$ that would store the *same* non-trivial information of all three matrices in a *single* 2D-matrix:\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/BK4NXCP.png\"></img>\n",
    "\n",
    "This matrix is the efficiently stored **Jacobian** $J=\\frac{\\partial \\vec h}{\\partial W}$. Using this matrix, the update-step simplifies to:\n",
    "\n",
    "$$\n",
    "W = W - \\text{learning_rate}\\cdot J\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "For example, for input vector $\\vec x=[1, 2]$ the efficiently stored Jacobian is:\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/khVlJIY.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([1, 2])\n",
      "W: torch.Size([2, 3])\n",
      "h: torch.Size([1, 3])\n",
      "\n",
      "=> Jacobian/Jacobian Product:\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# The same example in pytorch\n",
    "# https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#optional-reading-tensor-gradients-and-jacobian-products\n",
    "\n",
    "import torch\n",
    "x = torch.Tensor([1, 2]).reshape((1, -1))\n",
    "W = torch.randn((2, 3), requires_grad=True)\n",
    "h = x@W\n",
    "print(f\"x: {x.shape}\\nW: {W.shape}\\nh: {h.shape}\")\n",
    "\n",
    "# Normally, we want to compute the gradient of a *scalar* function w.r.t. to some\n",
    "# parameters. In that case we can simply call f.backward()\n",
    "# But here, we want to compute the gradient of a *vector-valued* function w.r.t. some\n",
    "# parameters. In that case f.backward() will compute the *Jacobian product*, and not\n",
    "# the actual gradient, see https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#optional-reading-tensor-gradients-and-jacobian-products\n",
    "v = torch.ones_like(h)\n",
    "h.backward(v)\n",
    "J = W.grad # computes v.T@J for input vector v=(v1, ..., vm)\n",
    "print(f\"\\n=> Jacobian/Jacobian Product:\\n{J}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is the jacobian product *not* the actual gradient?**\n",
    "\n",
    "See https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#optional-reading-tensor-gradients-and-jacobian-products\n",
    "\n",
    "* \"the gradient is subset of the Jacobian.\" \n",
    "* \"the gradient can be seen as special case of the Jacobian, i.e. when the function is scalar\"\n",
    "* \"The Jacobian matrix is the matrix formed by the partial derivatives of a vector function. Its vectors are the gradients of the respective components of the function.\" => The Jacobian stores the GRADIENTS of the components of the function in its columns/rows!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backprop, chain rule, storing gradients along the forward path \n",
    "\n",
    "* We extend the example above by adding an output layer associated with weights $\\vec w^{(out)}=[w_1^{(out)}, w_2^{(out)}, w_3^{(out)}]$, that takes in $\\vec h=[h_1, h_2, h_3]$ and computes $score=\\vec w^{(out)}\\vec h=w_1^{(out)}h_1 + w_2^{(out)}h_2 + w_3^{(out)}h_3$. \n",
    "* Then `score` can then be pushed through a sigmoid function to be turned into a probability: $prob=\\sigma(score)$. \n",
    "* Then `prob` can be compared with the actual target via some loss function $Loss(prob, target)$.\n",
    "* Then updating the weights $W$ and $w^{(out)}$ is a matter of finding the derivatives `dLoss/dW` and `dLoss/dwout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([3]) torch.Size([]) torch.Size([]) torch.Size([1])\n",
      "tensor([0.9821], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import relu\n",
    "from torch import sigmoid\n",
    "\n",
    "# input vector and target\n",
    "x = torch.Tensor([1, 2])\n",
    "t = torch.Tensor([1])\n",
    "\n",
    "# init the network\n",
    "W = torch.randn((2, 3), requires_grad=True)\n",
    "wout = torch.randn(3, requires_grad=True)\n",
    "\n",
    "# forward pass\n",
    "h = x@W\n",
    "hact = relu(h)\n",
    "score = hact@wout\n",
    "prob = sigmoid(score)\n",
    "loss = (prob - t)**2\n",
    "\n",
    "print(h.shape, hact.shape, score.shape, prob.shape, loss.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass, but storing storing gradients on the way\n",
    "h = x@W\n",
    "dh_dW = x.repeat(3).reshape((3, 2)).T \n",
    "\n",
    "hact = relu(h)\n",
    "dhact_dh = torch.zeros_like(hact)\n",
    "dhact_dh[hact > 0] = 1.0 # dReLU(x)/dx=1 if x>0 else 0\n",
    "\n",
    "score = hact@wout\n",
    "dscore_dwout = hact\n",
    "dscore_dhact = wout\n",
    "\n",
    "prob = sigmoid(score)\n",
    "dprob_dscore = sigmoid(score)*(1-sigmoid(score))\n",
    "\n",
    "loss = (prob - t)**2\n",
    "dloss_dprob = 2*(prob-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dloss/dprob  = tensor([-1.9820], grad_fn=<MulBackward0>)\n",
      "dprob/dscore = 0.00891814474016428\n",
      "dscore/dwout = tensor([0.0000, 1.6959, 3.3641], grad_fn=<ReluBackward0>)\n",
      "\n",
      "dloss/dwout = tensor([-0.0000, -0.0300, -0.0595], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# compute the gradient dloss/dwout\n",
    "\n",
    "# required intermediate derivatives\n",
    "print(f\"dloss/dprob  = {dloss_dprob}\")\n",
    "print(f\"dprob/dscore = {dprob_dscore}\")\n",
    "print(f\"dscore/dwout = {dscore_dwout}\\n\")\n",
    "\n",
    "# apply chain rule\n",
    "dloss_dwout = dloss_dprob * dprob_dscore * dscore_dwout\n",
    "print(f\"dloss/dwout = {dloss_dwout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dloss/dprob  \t= tensor([-1.9820], grad_fn=<MulBackward0>)\n",
      "dprob/dscore \t= 0.00891814474016428\n",
      "dscore/dhact \t= tensor([-1.3249,  0.1077, -1.4519], requires_grad=True)\n",
      "dhact/dh \t= tensor([0., 1., 1.])\n",
      "dh/dW \t\t=\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n",
      "\n",
      "dloss/dW = \n",
      "tensor([[ 0.0000, -0.0019,  0.0257],\n",
      "        [ 0.0000, -0.0038,  0.0513]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# compute the gradient dloss/dW\n",
    "\n",
    "# required intermediate derivatives\n",
    "print(f\"dloss/dprob  \\t= {dloss_dprob}\")\n",
    "print(f\"dprob/dscore \\t= {dprob_dscore}\")\n",
    "print(f\"dscore/dhact \\t= {dscore_dhact}\")\n",
    "print(f\"dhact/dh \\t= {dhact_dh}\")\n",
    "print(f\"dh/dW \\t\\t=\\n{dh_dW}\\n\")\n",
    "\n",
    "# apply chain rule\n",
    "dloss_dW = dloss_dprob * dprob_dscore * dscore_dhact * dhact_dh * dh_dW\n",
    "print(f\"dloss/dW = \\n{dloss_dW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== dLoss/dwout ======\n",
      "pytorch grad: \ttensor([-0.0000, -0.0300, -0.0595])\n",
      "our grad: \ttensor([-0.0000, -0.0300, -0.0595], grad_fn=<MulBackward0>)\n",
      "\n",
      "====== dLoss/dW ======\n",
      "pytorch grad: \n",
      "tensor([[ 0.0000, -0.0019,  0.0257],\n",
      "        [ 0.0000, -0.0038,  0.0513]])\n",
      "\n",
      "our grad: \n",
      "tensor([[ 0.0000, -0.0019,  0.0257],\n",
      "        [ 0.0000, -0.0038,  0.0513]], grad_fn=<MulBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare our manually computed gradients against\n",
    "# gradients calculated by pytorch\n",
    "\n",
    "# zero gradients & re-do forward pass\n",
    "W.grad = None\n",
    "wout.grad = None\n",
    "h = x@W\n",
    "hact = relu(h)\n",
    "score = hact@wout\n",
    "prob = sigmoid(score)\n",
    "loss = (prob - t)**2\n",
    "loss.backward()\n",
    "\n",
    "# compare our gradients vs pytorch\n",
    "print(\"====== dLoss/dwout ======\")\n",
    "print(f\"pytorch grad: \\t{wout.grad}\\nour grad: \\t{dloss_dwout}\")\n",
    "print(\"\\n====== dLoss/dW ======\")\n",
    "print(f\"pytorch grad: \\n{W.grad}\\n\\nour grad: \\n{dloss_dW}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> WE GET THE SAME GRADIENTS AS PYTORCH**\n",
    "\n",
    "Notes\n",
    "\n",
    "* I think the gradients of `dloss_dW` and `dloss_dwout` were only properly calculated via the chain rule because pytorch does smart things when multiplying tensors using `*`\n",
    "    * TODO: understand how pytorch implements `scalar * vector` and `vector * matrix`, and how this translates to actual mathematical notation on paper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.0000, 2.0000],\n",
      "        [1.0000, 2.0000, 4.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5, 1. , 2. ],\n",
       "       [1. , 2. , 4. ]], dtype=float32)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "a = torch.Tensor([0.5, 1, 2])\n",
    "B = torch.Tensor([[1, 1, 1],\n",
    "                  [2, 2, 2]])\n",
    "\n",
    "print(a*B)\n",
    "\n",
    "# compare with numpy\n",
    "a = a.numpy()\n",
    "B = B.numpy()\n",
    "a*B\n",
    "\n",
    "# => both yield same result...\n",
    "# TODO: how would I calculate these manually on paper? How would\n",
    "# I write down multiplication of vector * matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old notes I dont want to delete yet\n",
    "\n",
    "Here are the steps visualized:\n",
    "\n",
    "```\n",
    "x = [x1, x2]     # a single observation has 2 features\n",
    "h = [h1, h2, h3] # hidden layer with 3 neurons with states h1, h2, h3\n",
    "```\n",
    "\n",
    "The weights of each of the three neurons correspond to a column\n",
    "\n",
    "```\n",
    "W = [[W11, W12, W13],\n",
    "     [W21, W22, W23]]\n",
    "```\n",
    "\n",
    "Then we can compute the hidden layer\n",
    "\n",
    "```\n",
    "h = xW = [h1, h2, h3] # shape(1x3)\n",
    "```\n",
    "\n",
    "* x:  shape(1x2)\n",
    "* W: shape(2x3)\n",
    "* h: shape(1x3)\n",
    "\n",
    "Then we run `h` through an output layer with a sigmoid activation function. That output layer has weights `v=[v1, v2, v3]`.\n",
    "\n",
    "```\n",
    "out = h@v = [h1 h2 h3] @ [v1 v2 v3] = h1*v1 + h2*v2 + h3*v3\n",
    "```\n",
    "\n",
    "To get a probability, we put the result through a sigmoid activation function:\n",
    "\n",
    "```\n",
    "prob = sigmoid(out)\n",
    "```\n",
    "\n",
    "We can put everything together:\n",
    "\n",
    "\n",
    "```\n",
    "f(x, W, v) = sigmoid(out)\n",
    "           = sigmoid(h @ v)\n",
    "           = sigmoid(xW @ v)\n",
    "```\n",
    "\n",
    "Our goal is now to find `dfdW` and `dfdv` because they are needed to update our weights `W` and `v`.\n",
    "\n",
    "Using the chain rule, we find `dfdW` as follows:\n",
    "\n",
    "```\n",
    "(1)   dprob/dout = sigmoid(out)*sigmoid(1-out)\n",
    "(2.1) dout/dv    = h\n",
    "(2.2) dout/dh    = v\n",
    "(3)   dh/dW = x\n",
    "```\n",
    "\n",
    "Applying the chain rule to get `df/dW` and `df/dv`:\n",
    "\n",
    "```\n",
    "df/dv = dprob/dout * dout/dv \n",
    "      = s(out)*s(1-out) * h\n",
    "\n",
    "df/dW = dprob/dout * dout/dh * dh/dW\n",
    "      = s(out)*s(1-out) * v * x\n",
    "```\n",
    "\n",
    "\n",
    "Now it's unclear how the vector-vector product `v*x = [v1 v2 v3] * [x1 x2]` is defined? In the end, we must get a (2x3) matrix. The only way to get that from a 3D and 2D vector is via the dot product `shape(2x1) @ shape(1x3) = shape(2x3)`, hence `x.T @ v.T`. But it's unclear why...Maybe it has to do with *Jacobians*?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
