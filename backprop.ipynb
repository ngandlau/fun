{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import relu\n",
    "from torch import sigmoid\n",
    "\n",
    "torch.set_printoptions(sci_mode=False) # disable scientific notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Helpful) References\n",
    "\n",
    "* http://cs231n.stanford.edu/vecDerivs.pdf\n",
    "* https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite 1: Vector-Matrix Gradient\n",
    "\n",
    "Suppose we have \n",
    "\n",
    "* observation $\\vec x$ shaped (1, D)\n",
    "* weight matrix $W$ shaped (D, H)\n",
    "* output $\\vec h=\\vec xW$ shaped (1, H)\n",
    "\n",
    "and we're looking for $\\frac{\\partial \\vec h}{\\partial W}$\n",
    "\n",
    "---\n",
    "\n",
    "<img style=\"max-width:400px;\" src=\"https://i.imgur.com/sG5UBMq.png\"></img>\n",
    "\n",
    "$\\vec h$ is a vector-valued function. We're looking for the derivative $\\frac{\\partial \\vec h}{\\partial W}$. This requires us to calculate partial derivatives of *each* element of h with respect to *each* element of W. That is, we have to calculate $\\frac{\\partial h_1}{\\partial W}, \\frac{\\partial h_2}{\\partial W}, \\frac{\\partial h_3}{\\partial W}$. \n",
    "\n",
    "Each derivative $\\frac{\\partial h_i}{\\partial W}$ for $i=1,2,3$ consists of `(2*3)=6` partial derivatives because $W$ has `2*3` elements. These partial derivatives w.r.t. every element of matrix $W$ can be stored in a matrix of the same shape as $W$. Because $\\vec h$ has three elements $h_1, h_2, h_3$, we will get *three* of those matrices: $\\frac{\\partial h_1}{\\partial W}, \\frac{\\partial h_2}{\\partial W}, \\frac{\\partial h_3}{\\partial W}$.\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/oPLzvtc.png\"></img>\n",
    "\n",
    "Note that $h_i=\\vec x \\cdot W_{:,i}$. The calculation of $h_i$ only involves $x$ and column $i$ of $W$. Thus, when we take the derivative $\\frac{\\partial h_i}{\\partial W}$, only the partial derivatives $\\frac{\\partial h_i}{\\partial W_{j,k}}$ where $i=k$ are non-zero. We can summarise this as follows:\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/YZ7T3SQ.png\"></img>\n",
    "\n",
    "Using this, we can compute the partial derivatives:\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/thOmApu.png\"></img>\n",
    "\n",
    "These three matrices can now be used to update `W`. To update `W`, we would need to do three steps:\n",
    "\n",
    "1. $W = W - \\text{learning_rate}\\cdot \\frac{\\partial h_1}{\\partial W}$\n",
    "1. $W = W - \\text{learning_rate}\\cdot \\frac{\\partial h_2}{\\partial W}$\n",
    "1. $W = W - \\text{learning_rate}\\cdot \\frac{\\partial h_3}{\\partial W}$\n",
    "\n",
    "or, equivalently,\n",
    "\n",
    "$$\n",
    "W = W - \\text{learning_rate}*(\\frac{\\partial h_1}{\\partial W} + \\frac{\\partial h_2}{\\partial W} + \\frac{\\partial h_3}{\\partial W})\n",
    "$$\n",
    "\n",
    "But there is a trick (see Section 3 of http://cs231n.stanford.edu/vecDerivs.pdf) that (1) simplifies the update-step and (2) helps storing the three matrices more efficiently. For this trick, note that most elements of the three matrices are zero. In fact, the only non-zero elements $\\frac{\\partial h_i}{\\partial W_{jk}}$ of $\\frac{\\partial h_i}{\\partial W}$ are those elements where $i=k$. We could define a new matrix $J_{j,i}=\\frac{\\partial h_i}{\\partial W_{ji}}$ that would store the *same* non-trivial information of all three matrices in a *single* 2D-matrix:\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/BK4NXCP.png\"></img>\n",
    "\n",
    "This matrix is the efficiently stored **Jacobian** $J=\\frac{\\partial \\vec h}{\\partial W}$. Using this matrix, the update-step simplifies to:\n",
    "\n",
    "$$\n",
    "W = W - \\text{learning_rate}\\cdot J\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "For example, for input vector $\\vec x=[1, 2]$ the efficiently stored Jacobian is:\n",
    "\n",
    "<img style=\"max-width:500px;\" src=\"https://i.imgur.com/khVlJIY.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([1, 2])\n",
      "W: torch.Size([2, 3])\n",
      "h: torch.Size([1, 3])\n",
      "dh/dW:\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# The same example in pytorch\n",
    "# https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#optional-reading-tensor-gradients-and-jacobian-products\n",
    "\n",
    "x = torch.Tensor([1, 2]).reshape((1, -1))\n",
    "W = torch.randn((2, 3), requires_grad=True)\n",
    "h = x@W\n",
    "print(f\"x: {x.shape}\\nW: {W.shape}\\nh: {h.shape}\")\n",
    "\n",
    "h.backward(torch.ones_like(h))\n",
    "dhdW = W.grad \n",
    "print(f\"dh/dW:\\n{J}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is the jacobian product *not* the actual gradient?**\n",
    "\n",
    "See https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#optional-reading-tensor-gradients-and-jacobian-products\n",
    "\n",
    "* \"the gradient is subset of the Jacobian.\" \n",
    "* \"the gradient can be seen as special case of the Jacobian, i.e. when the function is scalar\"\n",
    "* \"The Jacobian matrix is the matrix formed by the partial derivatives of a vector function. Its vectors are the gradients of the respective components of the function.\" => The Jacobian stores the GRADIENTS of the components of the function in its rows!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension to multiple data points stored in a data matrix $X$\n",
    "\n",
    "Previously, we had observation $\\vec x$ and weight matrix $W$, and wanted to compute $\\vec h = \\vec x W$.\n",
    "\n",
    "Now we have data matrix $X$ shaped $(N, D)$, which stores $N$ observations $\\vec x_1, \\dots, \\vec x_N$ in its rows.\n",
    "\n",
    "We have the same goal of calculating $H=XW$. \n",
    "\n",
    "Note that $H$ is now a (N, H) matrix. Each row of $H$ contains the hidden state $\\vec h_i=\\vec x_i W$, calculated using observation $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [10., 20.]])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, D, n_hidden = 2, 2, 3\n",
    "\n",
    "# create data matrix X\n",
    "x1 = torch.tensor([1., 2.])\n",
    "x2 = torch.tensor([10., 20.])\n",
    "X = torch.cat([x1 , x2]).reshape(N, D)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4463, -0.7549, -0.3479],\n",
       "        [-0.3383,  2.6471, -0.3953]], requires_grad=True)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init weight matrix W\n",
    "W = torch.randn((D, n_hidden), requires_grad=True)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.2304,   4.5393,  -1.1385],\n",
       "        [ -2.3036,  45.3927, -11.3849]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate matrix containing hidden states h1, h2\n",
    "H = X@W\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 11., 11.],\n",
       "        [22., 22., 22.]])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dH/dW \n",
    "H.backward(torch.ones_like(W))\n",
    "W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> `dH/dW` is the sum of Jacobians of $\\vec h1, \\vec h2$.\n",
    "\n",
    "Recall that\n",
    "\n",
    "$$\n",
    "H = \n",
    "\\begin{bmatrix}\n",
    "- \\vec{h_1} - \\\\\n",
    "- \\vec{h_2} -\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $\\vec h_1$ is the hidden-state computed using observation $\\vec x_1$ (row 1 of $X$)\n",
    "* $\\vec h_2$ is the hidden-state computed using observation $\\vec x_2$ (row 2 of $X$)\n",
    "\n",
    "We previously derived the Jacobians of a vector-matrix derivative. We use this to get $\\vec h_1, \\vec h_2$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\vec h_1}{\\partial W}=\n",
    "\\begin{bmatrix}\n",
    "X_{1,1} & X_{1,1} & X_{1, 1} \\\\\n",
    "X_{1,2} & X_{1,2} & X_{1, 2}\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\vec h_2}{\\partial W}=\n",
    "\\begin{bmatrix}\n",
    "X_{2,1} & X_{2,1} & X_{2, 1} \\\\\n",
    "X_{2,2} & X_{2,2} & X_{2, 2}\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "So that:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\vec H}{\\partial W} & =\n",
    "\\begin{bmatrix}\n",
    "X_{1,1} & X_{1,1} & X_{1, 1} \\\\\n",
    "X_{1,2} & X_{1,2} & X_{1, 2}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "X_{2,1} & X_{2,1} & X_{2, 1} \\\\\n",
    "X_{2,2} & X_{2,2} & X_{2, 2}\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "& =\n",
    "\\begin{bmatrix}\n",
    "X_{1,1}+X_{2,1} & X_{1,1}+X_{2,1} & X_{1,1}+X_{2, 1} \\\\\n",
    "X_{1,2}+X_{2,2} & X_{1,2}+X_{2,2} & X_{1,2}+X_{2, 2}\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "& = \n",
    "\\begin{bmatrix}\n",
    "1+10 & 1+10 & 1+10 \\\\\n",
    "2+20 & 2+20 & 2+20\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "& = \n",
    "\\begin{bmatrix}\n",
    "11 & 11 & 11 \\\\\n",
    "22 & 22 & 22\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 11., 11.],\n",
       "        [22., 22., 22.]])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dH_dW = torch.sum(X.T, dim=1).repeat(n_hidden, 1).T # sum of jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000, -20.3211,  18.7920],\n",
       "        [  0.0000, -40.6421,  37.5840]])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extension where I push H through output layer\n",
    "N, D, n_hidden = 2, 2, 3\n",
    "\n",
    "X = torch.tensor([[1., 2.], [10., 20.]])\n",
    "W = torch.randn((D, n_hidden), requires_grad=True)\n",
    "wout = torch.randn((n_hidden), requires_grad=True)\n",
    "\n",
    "# forward with storing gradients along the way\n",
    "H = X@W\n",
    "dH_dW = torch.sum(X.T, dim=1).repeat(n_hidden, 1).T # sum of N Jacobians\n",
    "\n",
    "Hact = relu(H)\n",
    "dHact_dH = (H > 0).to(torch.float32)\n",
    "\n",
    "score = Hact@wout\n",
    "dscore_dHact = wout.repeat(1, 2).reshape((2, 3))\n",
    "\n",
    "score.backward(torch.ones_like(x))\n",
    "W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3943, -1.8474,  1.7084],\n",
      "        [-1.3943, -1.8474,  1.7084]], grad_fn=<ViewBackward>)\n",
      "tensor([[0., 1., 1.],\n",
      "        [0., 1., 1.]])\n",
      "tensor([[11., 11., 11.],\n",
      "        [22., 22., 22.]])\n",
      "tensor([[ -0.0000, -20.3211,  18.7920],\n",
      "        [ -0.0000, -40.6421,  37.5840]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(dscore_dHact)\n",
    "print(dHact_dH)\n",
    "print(dH_dW)\n",
    "dscore_dW = dH_dW * dHact_dH * dscore_dHact\n",
    "print(dscore_dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_matrix_derivative(W, x):\n",
    "    \"\"\"\n",
    "    Function for computing the derivative of y=xW w.r.t. W,\n",
    "    ie dy/dW.\n",
    "        \n",
    "    Args:\n",
    "        W (torch.tensor): matrix shaped (D, H)\n",
    "        x (torch.tensor): vector shaped (D) or matrix shaped (N, D)\n",
    "    \n",
    "    Returns:\n",
    "        gradient dy/dW, a torch.tensor of the same shape as W\n",
    "    \n",
    "    Note:\n",
    "        y=xW: output shaped (1, H) or (N, H)\n",
    "        \n",
    "    Explanation: \n",
    "        dy/dW will be the sum of the scalar-matrix derivatives\n",
    "        (=Jacobians) dyi/dW, where yi is the i'th element of y.\n",
    "    \"\"\"\n",
    "    # if x is a single observation vector shaped (D)\n",
    "    if len(x.shape) == 1:\n",
    "        dy_dW = x.reshape(-1, 1).repeat(1, W.shape[1]) \n",
    "    # if x is a data matrix shaped (N, D)\n",
    "    elif len(x.shape) == 2:\n",
    "        dy_dW = torch.sum(x, dim=0).reshape(-1, 1).repeat(1, W.shape[1])\n",
    "    else:\n",
    "        return \"x must be a (1, D) vector or a (N, D) data matrix\"\n",
    "    return dy_dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch grad: \n",
      " tensor([[5., 5., 5., 5.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [9., 9., 9., 9.]])\n",
      " our grad: \n",
      " tensor([[5., 5., 5., 5.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [9., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "x = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "W = torch.randn((3, 4), requires_grad=True)\n",
    "y = x@W\n",
    "dy_dW = vector_matrix_derivative(W, x)\n",
    "y.backward(torch.ones_like(y))\n",
    "dy_dW_pytorch = W.grad\n",
    "\n",
    "print(f\"pytorch grad: \\n {dy_dW_pytorch}\\n our grad: \\n {dy_dW}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: backprop of a single observation $\\vec x$\n",
    "\n",
    "<img style=\"max-width: 500px;\" src=\"https://i.imgur.com/Y6R3i5L.png\"></img>\n",
    "\n",
    "* The hidden layer takes in $\\vec x$ and calculates $\\vec h=xW$.\n",
    "* Then $h$ is activated $\\vec h_{act}=ReLU(\\vec h)$.\n",
    "* Then $h_{act}$ is run through the output layer: $score=\\vec h_{act}\\vec w^{out}$\n",
    "* Then $score$,  a scalar, is finally through a sigmoid function to get a probability $prob=\\sigma(score)$. \n",
    "* Then $prob$, a scalar, is compared with the target via the loss function $Loss(prob, target)=(prob-target)^2$.\n",
    "* Then updating the weights $W$ and $w^{(out)}$ is a matter of finding the derivatives `dLoss/dW` and `dLoss/dwout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, n_hidden = 1, 2, 3\n",
    "\n",
    "# input vector and target\n",
    "x = torch.Tensor([1, 2])\n",
    "t = torch.Tensor([1])\n",
    "\n",
    "# init the network\n",
    "W = torch.randn((D, n_hidden), requires_grad=True)\n",
    "wout = torch.randn(n_hidden, requires_grad=True)\n",
    "\n",
    "# forward pass\n",
    "h = x@W\n",
    "hact = relu(h)\n",
    "score = hact@wout\n",
    "prob = sigmoid(score)\n",
    "loss = (prob - t)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass, but storing storing gradients on the way\n",
    "h = x@W\n",
    "# dh_dW = x.repeat(n_hidden).reshape((n_hidden, D)).T \n",
    "dh_dW = vector_matrix_derivative(W, x)\n",
    "\n",
    "hact = relu(h)\n",
    "dhact_dh = (h > 0).to(torch.float32) # dReLU(x)/dx=1 if x>0 else 0\n",
    "\n",
    "score = hact@wout\n",
    "dscore_dwout = hact # required for dLoss/dW\n",
    "dscore_dhact = wout # required for dLoss/dwout\n",
    "\n",
    "prob = sigmoid(score)\n",
    "dprob_dscore = sigmoid(score)*(1-sigmoid(score))\n",
    "\n",
    "loss = (prob - t)**2\n",
    "dloss_dprob = 2*(prob-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dloss/dprob  = tensor([-1.7710], grad_fn=<MulBackward0>)\n",
      "dprob/dscore = 0.10139695554971695\n",
      "dscore/dwout = tensor([0.0000, 1.9175, 0.0000], grad_fn=<ReluBackward0>)\n",
      "=== RESULT ===\n",
      "dloss/dwout = tensor([-0.0000, -0.3443, -0.0000], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# compute the gradient dloss/dwout\n",
    "\n",
    "# required intermediate derivatives for chain rule\n",
    "print(f\"dloss/dprob  = {dloss_dprob}\")\n",
    "print(f\"dprob/dscore = {dprob_dscore}\")\n",
    "print(f\"dscore/dwout = {dscore_dwout}\")\n",
    "\n",
    "# apply chain rule\n",
    "dloss_dwout = dloss_dprob * dprob_dscore * dscore_dwout\n",
    "print(f\"=== RESULT ===\\ndloss/dwout = {dloss_dwout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dloss/dprob  \t= tensor([-1.7710], grad_fn=<MulBackward0>)\n",
      "dprob/dscore \t= 0.10139695554971695\n",
      "dscore/dhact \t= tensor([ 0.7842, -1.0667, -0.1411], requires_grad=True)\n",
      "dhact/dh \t= tensor([0., 1., 0.])\n",
      "dh/dW \t\t=\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n",
      "=== RESULT ===\n",
      "dloss/dW = \n",
      "tensor([[-0.0000, 0.1916, 0.0000],\n",
      "        [-0.0000, 0.3831, 0.0000]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# compute the gradient dloss/dW\n",
    "\n",
    "# required intermediate derivatives\n",
    "print(f\"dloss/dprob  \\t= {dloss_dprob}\")\n",
    "print(f\"dprob/dscore \\t= {dprob_dscore}\")\n",
    "print(f\"dscore/dhact \\t= {dscore_dhact}\")\n",
    "print(f\"dhact/dh \\t= {dhact_dh}\")\n",
    "print(f\"dh/dW \\t\\t=\\n{dh_dW}\")\n",
    "\n",
    "# apply chain rule\n",
    "dloss_dW = dloss_dprob * dprob_dscore * dscore_dhact * dhact_dh * dh_dW\n",
    "print(f\"=== RESULT ===\\ndloss/dW = \\n{dloss_dW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== dLoss/dwout ======\n",
      "pytorch grad: \ttensor([-0.0000, -0.3443, -0.0000])\n",
      "our grad: \ttensor([-0.0000, -0.3443, -0.0000], grad_fn=<MulBackward0>)\n",
      "\n",
      "====== dLoss/dW ======\n",
      "pytorch grad: \n",
      "tensor([[0.0000, 0.1916, 0.0000],\n",
      "        [0.0000, 0.3831, 0.0000]])\n",
      "\n",
      "our grad: \n",
      "tensor([[-0.0000, 0.1916, 0.0000],\n",
      "        [-0.0000, 0.3831, 0.0000]], grad_fn=<MulBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare our manually computed gradients vs pytorch\n",
    "\n",
    "# zero gradients & re-do forward pass\n",
    "W.grad = None\n",
    "wout.grad = None\n",
    "h = x@W\n",
    "hact = relu(h)\n",
    "score = hact@wout\n",
    "prob = sigmoid(score)\n",
    "loss = (prob - t)**2\n",
    "loss.backward()\n",
    "\n",
    "# compare our gradients vs pytorch\n",
    "print(\"====== dLoss/dwout ======\")\n",
    "print(f\"pytorch grad: \\t{wout.grad}\\nour grad: \\t{dloss_dwout}\")\n",
    "print(\"\\n====== dLoss/dW ======\")\n",
    "print(f\"pytorch grad: \\n{W.grad}\\n\\nour grad: \\n{dloss_dW}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> WE GET THE SAME GRADIENTS AS PYTORCH**\n",
    "\n",
    "Notes: \n",
    "\n",
    "* TODO: understand how pytorch implements `scalar * vector` and `vector * matrix`, and how this translates to actual mathematical notation on paper! Otherwise I don't fully understand what happens when we apply the chain rule, where I multiply differently shaped scalars/vectors/matrices.\n",
    "* ReLU activation function\n",
    "    * The derivative of ReLU(x) is interesting. It's either 1 or 0. If it's 1, we allow the gradient *as is* to be backpropagated from that point further backwards. If it's 0, then the gradient will be 0, no gradient will be backpropagated from that point further backwards.\n",
    "    * ReLU(x) only lets gradients of *activated* neurons through. Here, activated means x>0.\n",
    "    * ReLu solves the **vanishing gradient problem**. The vanishing gradient problem exists especially in deeper networks that uses e.g. sigmoid activation functions. Because the sigmoid activation function is ~0 for high and low x...ReLU is only 0 for low x...\n",
    "    * we want neurons to fire when they detect their pattern or \"concept\". when the pattern is *very* present, we want big positive numbers. when it is not present, the neuron should not fire at all. Intuitively, a pattern cannot be \"less\" than not present. And if 0 represents \"not present\", then a value *below* 0 does not make sense. Hence we can intuitively justify setting ReLU(x)=0 if x<0.\n",
    "    * **dying relu problem**: when there is e.g. a *large negative bias term* that always makes the pre-activation negative. In that case, we always get ReLU(a)=0 for that neuron, and so the neuron *never* learns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backprop of multiple observations stored in data matrix X\n",
    "\n",
    "* repeat the stuff we did with a single observation, but for N observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input vector and target (now a batch of 2 observation)\n",
    "X = torch.Tensor([[1, 2], [3, 4]])\n",
    "t = torch.arange(X.shape[0])\n",
    "\n",
    "N, D = X.shape\n",
    "n_hidden = 3\n",
    "\n",
    "# init the network (same architecture as before)\n",
    "W = torch.randn((D, n_hidden), requires_grad=True)\n",
    "wout = torch.randn(n_hidden, requires_grad=True)\n",
    "\n",
    "# forward pass\n",
    "h = X@W               # X: shape(N, D), W: shape(D, H)   => H: shape(N, H)\n",
    "hact = relu(h)        # H: shape(N, H)                   => Hact: shape(N, H)\n",
    "score = hact@wout     # Hact: shape(N, H), wout=shape(H) => score: shape(N)\n",
    "prob = sigmoid(score) # score: shape(N)                  => prob: shape(N)\n",
    "loss = (prob - t)**2  # prob: shape(N), t: shape(N)      => loss: shape(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# forward pass, but storing storing gradients along the way\n",
    "H = X@W\n",
    "dH_dW = vector_matrix_derivative(W, X)\n",
    "\n",
    "Hact = relu(H) # shape(N, H)\n",
    "dHact_dH = (H > 0).to(torch.float32)\n",
    "\n",
    "score = Hact@wout # shape(N)\n",
    "dscore_dwout = Hact\n",
    "dscore_dHact = vector_matrix_derivative(Hact, wout)\n",
    "print(score.shape, dscore_dHact.shape)\n",
    "\n",
    "prob = sigmoid(score)\n",
    "dprob_dscore = sigmoid(score)*(1-sigmoid(score))\n",
    "\n",
    "loss = (prob - t)**2\n",
    "dloss_dprob = 2*(prob-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dloss/dprob  = tensor([ 0.8328, -1.2002], grad_fn=<MulBackward0>)\n",
      "dprob/dscore = tensor([0.2430, 0.2400], grad_fn=<MulBackward0>)\n",
      "dscore/dwout =\n",
      " tensor([[0.7286, 0.0000, 0.7915],\n",
      "        [1.0827, 0.0000, 1.6188]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "dloss/dwout =\n",
      " tensor([-0.1644,  0.0000, -0.3061], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# compute the gradient dloss/dwout\n",
    "\n",
    "# required intermediate derivatives\n",
    "print(f\"dloss/dprob  = {dloss_dprob}\")\n",
    "print(f\"dprob/dscore = {dprob_dscore}\")\n",
    "print(f\"dscore/dwout =\\n {dscore_dwout}\\n\")\n",
    "\n",
    "# apply chain rule\n",
    "dloss_dwout = (dloss_dprob * dprob_dscore * dscore_dwout.T).T\n",
    "dloss_dwout = torch.sum(dloss_dwout, dim=0) # assumption: loss.sum()!\n",
    "print(f\"dloss/dwout =\\n {dloss_dwout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== dLoss/dwout ======\n",
      "pytorch grad: \ttensor([-0.1644,  0.0000, -0.3061])\n",
      "our grad: \ttensor([-0.1644,  0.0000, -0.3061], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# compare with pytorch\n",
    "W.grad = None\n",
    "wout.grad = None\n",
    "h = X@W\n",
    "hact = relu(h)\n",
    "score = hact@wout\n",
    "prob = sigmoid(score)\n",
    "loss = (prob - t)**2\n",
    "loss.sum().backward()\n",
    "\n",
    "# compare our gradients vs pytorch\n",
    "print(\"====== dLoss/dwout ======\")\n",
    "print(f\"pytorch grad: \\t{wout.grad}\\nour grad: \\t{dloss_dwout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dloss/dprob  \t= tensor([ 0.8328, -1.2002], grad_fn=<MulBackward0>)\n",
      "dprob/dscore \t= tensor([0.2430, 0.2400], grad_fn=<MulBackward0>)\n",
      "dscore/dhact =\n",
      " tensor([[-0.6984, -0.6984, -0.6984],\n",
      "        [ 0.4187,  0.4187,  0.4187],\n",
      "        [ 0.2163,  0.2163,  0.2163]], grad_fn=<RepeatBackward>)\n",
      "dhact/dh =\n",
      " tensor([[1., 0., 1.],\n",
      "        [1., 0., 1.]])\n",
      "dh/dW =\n",
      " tensor([[4., 4., 4.],\n",
      "        [6., 6., 6.]])\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-97aa8f002857>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# apply chain rule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdloss_dW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdloss_dprob\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdprob_dscore\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdscore_dHact\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdHact_dH\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdH_dW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"dloss/dW = \\n{dloss_dW}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# compute the gradient dloss/dW\n",
    "\n",
    "# required intermediate derivatives\n",
    "print(f\"dloss/dprob  \\t= {dloss_dprob}\")\n",
    "print(f\"dprob/dscore \\t= {dprob_dscore}\")\n",
    "print(f\"dscore/dhact =\\n {dscore_dHact}\") # this could be wrong...\n",
    "print(f\"dhact/dh =\\n {dHact_dH}\")\n",
    "print(f\"dh/dW =\\n {dH_dW}\\n\")\n",
    "\n",
    "# apply chain rule\n",
    "dloss_dW = dloss_dprob * dprob_dscore * dscore_dHact * dHact_dH * dH_dW\n",
    "print(f\"dloss/dW = \\n{dloss_dW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== dLoss/dW ======\n",
      "pytorch grad:\n",
      "tensor([[ 0.4621,  0.0000, -0.1432],\n",
      "        [ 0.5220,  0.0000, -0.1617]])\n",
      "our grad: \n",
      "tensor([[-0.0000, 0.1916, 0.0000],\n",
      "        [-0.0000, 0.3831, 0.0000]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# compare our gradients vs pytorch\n",
    "W.grad = None\n",
    "wout.grad = None\n",
    "h = X@W\n",
    "hact = relu(h)\n",
    "score = hact@wout\n",
    "prob = sigmoid(score)\n",
    "loss = (prob - t)**2\n",
    "loss.sum().backward()\n",
    "print(\"====== dLoss/dW ======\")\n",
    "print(f\"pytorch grad:\\n{W.grad}\\nour grad: \\n{dloss_dW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  0],\n",
       "        [ 2, 10],\n",
       "        [ 3, 20]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0, 1])\n",
    "A = torch.tensor([[1, 2, 3], [0, 10, 20]])\n",
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what i know\n",
    "\n",
    "* I know how to do backpropagation for a single example $\\vec x$, but I cannot do it for a batch of observations $X$\n",
    "* The problem lies in the calculation of derivatives. Probably I'm doing Vector-by-Matrix gradients wrong. \n",
    "    * http://cs231n.stanford.edu/slides/2018/cs231n_2018_ds02.pdf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old notes I dont want to delete yet\n",
    "\n",
    "Here are the steps visualized:\n",
    "\n",
    "```\n",
    "x = [x1, x2]     # a single observation has 2 features\n",
    "h = [h1, h2, h3] # hidden layer with 3 neurons with states h1, h2, h3\n",
    "```\n",
    "\n",
    "The weights of each of the three neurons correspond to a column\n",
    "\n",
    "```\n",
    "W = [[W11, W12, W13],\n",
    "     [W21, W22, W23]]\n",
    "```\n",
    "\n",
    "Then we can compute the hidden layer\n",
    "\n",
    "```\n",
    "h = xW = [h1, h2, h3] # shape(1x3)\n",
    "```\n",
    "\n",
    "* x:  shape(1x2)\n",
    "* W: shape(2x3)\n",
    "* h: shape(1x3)\n",
    "\n",
    "Then we run `h` through an output layer with a sigmoid activation function. That output layer has weights `v=[v1, v2, v3]`.\n",
    "\n",
    "```\n",
    "out = h@v = [h1 h2 h3] @ [v1 v2 v3] = h1*v1 + h2*v2 + h3*v3\n",
    "```\n",
    "\n",
    "To get a probability, we put the result through a sigmoid activation function:\n",
    "\n",
    "```\n",
    "prob = sigmoid(out)\n",
    "```\n",
    "\n",
    "We can put everything together:\n",
    "\n",
    "\n",
    "```\n",
    "f(x, W, v) = sigmoid(out)\n",
    "           = sigmoid(h @ v)\n",
    "           = sigmoid(xW @ v)\n",
    "```\n",
    "\n",
    "Our goal is now to find `dfdW` and `dfdv` because they are needed to update our weights `W` and `v`.\n",
    "\n",
    "Using the chain rule, we find `dfdW` as follows:\n",
    "\n",
    "```\n",
    "(1)   dprob/dout = sigmoid(out)*sigmoid(1-out)\n",
    "(2.1) dout/dv    = h\n",
    "(2.2) dout/dh    = v\n",
    "(3)   dh/dW = x\n",
    "```\n",
    "\n",
    "Applying the chain rule to get `df/dW` and `df/dv`:\n",
    "\n",
    "```\n",
    "df/dv = dprob/dout * dout/dv \n",
    "      = s(out)*s(1-out) * h\n",
    "\n",
    "df/dW = dprob/dout * dout/dh * dh/dW\n",
    "      = s(out)*s(1-out) * v * x\n",
    "```\n",
    "\n",
    "\n",
    "Now it's unclear how the vector-vector product `v*x = [v1 v2 v3] * [x1 x2]` is defined? In the end, we must get a (2x3) matrix. The only way to get that from a 3D and 2D vector is via the dot product `shape(2x1) @ shape(1x3) = shape(2x3)`, hence `x.T @ v.T`. But it's unclear why...Maybe it has to do with *Jacobians*?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
